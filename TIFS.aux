\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{DeAngeli:2005:PRW:1090412.1090419}
\citation{androidstudy}
\citation{aviv2010smudge}
\citation{zhang2016privacy}
\citation{kuhn2002compromising,balzarotti2008clearshot}
\citation{shukla2014beware}
\citation{aviv2010smudge}
\citation{shoulder}
\citation{alpnorway}
\select@language{american}
\@writefile{toc}{\select@language{american}}
\@writefile{lof}{\select@language{american}}
\@writefile{lot}{\select@language{american}}
\newlabel{sec:intro}{{I}{1}{Introduction}{section.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {I}Introduction}{1}{section.1}}
\citation{DBLP:conf/soups/2014}
\citation{standing1970perception,Weiss2008PassShapes}
\citation{uellenbeck2013quantifying}
\citation{Kelley2012Guess,Mazurek2013Measuring}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Examples of scenarios in which a mobile phone camera is used to film the unlocking process. In these scenarios, the camera does not need to have a clear sight of the screen.}}{2}{figure.1}}
\newlabel{fig:fig1}{{1}{2}{Examples of scenarios in which a mobile phone camera is used to film the unlocking process. In these scenarios, the camera does not need to have a clear sight of the screen}{figure.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {II}Background}{2}{section.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {II-A}}Android Pattern Lock}{2}{subsection.2.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {II-B}}Threat Model}{2}{subsection.2.2}}
\newlabel{sec:scenarios}{{\unhbox \voidb@x \hbox {II-B}}{2}{Threat Model}{subsection.2.2}{}}
\citation{shukla2014beware}
\citation{aviv2010smudge}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Overview of the attack. Our system takes in a video segment that records the unlocking process (a). The adversary first marks two areas of interest on the first video frame (b): one contains the fingertip involved in pattern drawing, and the other contains part of the device. Our system then tries to track the fingertip's location w.r.t. to the device. The tracking algorithm produces a fingertip movement trajectory from the camera's perspective (c) which is then transformed to the user's perspective (d). Finally, the resulted trajectory in (d) is mapped to several candidate patterns (e) to be tested on the target device (f). }}{3}{figure.2}}
\newlabel{fig:fig2}{{2}{3}{Overview of the attack. Our system takes in a video segment that records the unlocking process (a). The adversary first marks two areas of interest on the first video frame (b): one contains the fingertip involved in pattern drawing, and the other contains part of the device. Our system then tries to track the fingertip's location w.r.t. to the device. The tracking algorithm produces a fingertip movement trajectory from the camera's perspective (c) which is then transformed to the user's perspective (d). Finally, the resulted trajectory in (d) is mapped to several candidate patterns (e) to be tested on the target device (f)}{figure.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {III}Overview of Our Attack}{3}{section.3}}
\newlabel{section:overview}{{III}{3}{Overview of Our Attack}{section.3}{}}
\citation{kalal2012tracking}
\@writefile{toc}{\contentsline {section}{\numberline {IV}Implementation Details}{4}{section.4}}
\newlabel{sec:identify}{{\unhbox \voidb@x \hbox {IV-A}}{4}{Video preprocessing}{subsection.4.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {IV-A}}Video preprocessing }{4}{subsection.4.1}}
\newlabel{section:recognition}{{\unhbox \voidb@x \hbox {IV-A}}{4}{Video preprocessing}{subsection.4.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces The cumulative distribution function (CDF) of the time interval between pattern drawing and other on-screen activities.}}{4}{figure.3}}
\newlabel{fig:time-interval}{{3}{4}{The cumulative distribution function (CDF) of the time interval between pattern drawing and other on-screen activities}{figure.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Spatial-temporal characteristics for performing an on-screen gesture once (a, c, e) and twice (b, d, f).}}{4}{figure.4}}
\newlabel{fig:gesture-distinction}{{4}{4}{Spatial-temporal characteristics for performing an on-screen gesture once (a, c, e) and twice (b, d, f)}{figure.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {IV-B}}Track fingertip locations}{4}{subsection.4.2}}
\newlabel{section:tld}{{\unhbox \voidb@x \hbox {IV-B}}{4}{Track fingertip locations}{subsection.4.2}{}}
\citation{hastie1996discriminant}
\citation{kalal2012tracking}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Tracking the fingertip movement trajectory. For each video frame, the system tracks two areas: one surrounds the fingertip and the other covers the edge of the device. The fingertip position is determined by computing the relative coordinates of the central points of the two areas. The red points highlighted in the final results (d) are the touching points tracked from the three video frames.}}{5}{figure.5}}
\newlabel{fig:fig5}{{5}{5}{Tracking the fingertip movement trajectory. For each video frame, the system tracks two areas: one surrounds the fingertip and the other covers the edge of the device. The fingertip position is determined by computing the relative coordinates of the central points of the two areas. The red points highlighted in the final results (d) are the touching points tracked from the three video frames}{figure.5}{}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {1}{\ignorespaces Unlocking process identification heuristic}}{5}{algorithm.1}}
\newlabel{alg:recognition}{{1}{5}{Video preprocessing}{algorithm.1}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\unhbox \voidb@x \hbox {IV-B}1}Generate The Fingertip Movement Trajectory}{5}{subsubsection.4.2.1}}
\newlabel{secction:shake}{{\unhbox \voidb@x \hbox {IV-B}2}{5}{Camera Shake Calibration}{subsubsection.4.2.2}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\unhbox \voidb@x \hbox {IV-B}2}Camera Shake Calibration}{5}{subsubsection.4.2.2}}
\citation{grompone2010lsd}
\citation{Torralba:2002:DEI:628330.628820}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces The resulted fingertip movement trajectories without (a) and with (b) camera-shake calibration. The correct pattern is shown in (c). To aid clarity we have transformed (a) and (b) to the user's perspective.}}{6}{figure.6}}
\newlabel{fig:camera_shake_illu}{{6}{6}{The resulted fingertip movement trajectories without (a) and with (b) camera-shake calibration. The correct pattern is shown in (c). To aid clarity we have transformed (a) and (b) to the user's perspective}{figure.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Filming angle calculation. The filming angle, $\theta $, is the angle between the edge line of the device and a vertical line.}}{6}{figure.7}}
\newlabel{fig:line_detection}{{7}{6}{Filming angle calculation. The filming angle, $\theta $, is the angle between the edge line of the device and a vertical line}{figure.7}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\unhbox \voidb@x \hbox {IV-B}3}Noisy Points Calibration}{6}{subsubsection.4.2.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {IV-C}}Filming angle transformation}{6}{subsection.4.3}}
\newlabel{sec:transformation}{{\unhbox \voidb@x \hbox {IV-C}}{6}{Filming angle transformation}{subsection.4.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {IV-D}}Identify and rank candidate patterns}{6}{subsection.4.4}}
\newlabel{section:spea}{{\unhbox \voidb@x \hbox {IV-D}}{6}{Identify and rank candidate patterns}{subsection.4.4}{}}
\citation{Kutner2004Applied}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces This figure shows the tracked fingertip movement trajectory (a) of a pattern (b). Point S on (a) is the the starting point and points A, B, C, and D on (b) represent four turning points.}}{7}{figure.8}}
\newlabel{fig:fig6}{{8}{7}{This figure shows the tracked fingertip movement trajectory (a) of a pattern (b). Point S on (a) is the the starting point and points A, B, C, and D on (b) represent four turning points}{figure.8}{}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {2}{\ignorespaces Line Segment Identification}}{7}{algorithm.2}}
\newlabel{alg:turning-point}{{2}{7}{Identify and rank candidate patterns}{algorithm.2}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\unhbox \voidb@x \hbox {IV-D}1}Extracting Structure Information}{7}{subsubsection.4.4.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Separating two overlapping line segments by checking the number of overlapping points within a timeframe.}}{7}{figure.9}}
\newlabel{fig:line-idenfication}{{9}{7}{Separating two overlapping line segments by checking the number of overlapping points within a timeframe}{figure.9}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces All possible line directions for a $3 \times 3$ Android pattern grid.}}{7}{figure.10}}
\newlabel{fig:fig7}{{10}{7}{All possible line directions for a $3 \times 3$ Android pattern grid}{figure.10}{}}
\@writefile{lot}{\contentsline {table}{\numberline {I}{\ignorespaces Mappings from line slopes and fingertip-horizontal movements to direction numbers}}{8}{table.1}}
\newlabel{tab:slopes}{{I}{8}{Mappings from line slopes and fingertip-horizontal movements to direction numbers}{table.1}{}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {3}{\ignorespaces Candidate Pattern Identification Algorithm}}{8}{algorithm.3}}
\newlabel{alg:alg1}{{3}{8}{Extracting Structure Information}{algorithm.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces Possible mappings for the tracked fingertip movement trajectory presented in Figure~\ref  {fig:fig2} (d). }}{8}{figure.11}}
\newlabel{fig:fig3}{{11}{8}{Possible mappings for the tracked fingertip movement trajectory presented in Figure~\ref {fig:fig2} (d)}{figure.11}{}}
\newlabel{section:identity}{{\unhbox \voidb@x \hbox {IV-D}2}{8}{Map the Tracked Trajectory to Candidate Patterns}{subsubsection.4.4.2}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\unhbox \voidb@x \hbox {IV-D}2}Map the Tracked Trajectory to Candidate Patterns}{8}{subsubsection.4.4.2}}
\citation{uellenbeck2013quantifying,alpnorway}
\citation{sun2014dissecting}
\citation{vonZezschwitz:2015:EDB:2702123.2702202}
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces Illustrations of the terminologies used in Equation~\ref  {equ:compscore}.}}{9}{figure.12}}
\newlabel{fig:intersection-overlap}{{12}{9}{Illustrations of the terminologies used in Equation~\ref {equ:compscore}}{figure.12}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {13}{\ignorespaces Examples of patterns collected from our participants. Patterns are grouped into \emph  {simple}, \emph  {median} and \emph  {complex} categories, according to their complexity scores. }}{9}{figure.13}}
\newlabel{fig:fig8}{{13}{9}{Examples of patterns collected from our participants. Patterns are grouped into \emph {simple}, \emph {median} and \emph {complex} categories, according to their complexity scores}{figure.13}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {14}{\ignorespaces Three most complex patterns on a $3\times 3$ grid based on Equation~\ref  {equ:compscore}.}}{9}{figure.14}}
\newlabel{fig:most complex patterns}{{14}{9}{Three most complex patterns on a $3\times 3$ grid based on Equation~\ref {equ:compscore}}{figure.14}{}}
\newlabel{sec:setup}{{V}{9}{Experimental Setup}{section.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {V}Experimental Setup }{9}{section.5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {V-A}}Data Collection}{9}{subsection.5.1}}
\newlabel{section:locking patterns}{{\unhbox \voidb@x \hbox {V-A}}{9}{Data Collection}{subsection.5.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {V-B}}Pattern Complexity Classification}{9}{subsection.5.2}}
\newlabel{equ:compscore}{{2}{9}{Pattern Complexity Classification}{equation.5.2}{}}
\citation{TLD-toolbox-web}
\citation{egelman2014you}
\@writefile{lof}{\contentsline {figure}{\numberline {15}{\ignorespaces The distribution of complexity scores for the patterns given by our participants.}}{10}{figure.15}}
\newlabel{fig:pattern-strength}{{15}{10}{The distribution of complexity scores for the patterns given by our participants}{figure.15}{}}
\@writefile{lot}{\contentsline {table}{\numberline {II}{\ignorespaces Screen sizes for the test phones}}{10}{table.2}}
\newlabel{tab:locking-screen-size}{{II}{10}{Screen sizes for the test phones}{table.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {V-C}}Video Recording and Preprocessing}{10}{subsection.5.3}}
\@writefile{toc}{\contentsline {section}{\numberline {VI}Experimental Results}{10}{section.6}}
\newlabel{sec:overall_rate}{{\unhbox \voidb@x \hbox {VI-A}}{10}{Overall Success Rate}{subsection.6.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {VI-A}}Overall Success Rate }{10}{subsection.6.1}}
\citation{shoulder}
\@writefile{lof}{\contentsline {figure}{\numberline {16}{\ignorespaces For each pattern category, the figure shows the success rate using no more than 1, 2, 3, 4 and 5 attempts.}}{11}{figure.16}}
\newlabel{fig:fig10}{{16}{11}{For each pattern category, the figure shows the success rate using no more than 1, 2, 3, 4 and 5 attempts}{figure.16}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {17}{\ignorespaces The distribution of candidate patterns for each category. No more than 5 candidate patterns were generated by our algorithm. }}{11}{figure.17}}
\newlabel{fig:fig11}{{17}{11}{The distribution of candidate patterns for each category. No more than 5 candidate patterns were generated by our algorithm}{figure.17}{}}
\@writefile{lot}{\contentsline {table}{\numberline {III}{\ignorespaces Tracking precision vs filming distance}}{11}{table.3}}
\newlabel{tab:tab1}{{III}{11}{Tracking precision vs filming distance}{table.3}{}}
\newlabel{sec:distances}{{\unhbox \voidb@x \hbox {VI-B}}{11}{Impact of Filming Distances}{subsection.6.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {VI-B}}Impact of Filming Distances }{11}{subsection.6.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {18}{\ignorespaces Tracked fingertip trajectories (user's perspective) for the pattern shown in (d) from a video filmed from a distance of 2m (a), 3m (b), and 3.5m (c) respectively away from the target device. The tracking quality decreases when the filming distance is greater than 3m. }}{12}{figure.18}}
\newlabel{fig:distance-show}{{18}{12}{Tracked fingertip trajectories (user's perspective) for the pattern shown in (d) from a video filmed from a distance of 2m (a), 3m (b), and 3.5m (c) respectively away from the target device. The tracking quality decreases when the filming distance is greater than 3m}{figure.18}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {19}{\ignorespaces Impact of the filming distance.}}{12}{figure.19}}
\newlabel{fig:fig12}{{19}{12}{Impact of the filming distance}{figure.19}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {20}{\ignorespaces The cumulative distribution function (CDF) for different video recording modes.}}{12}{figure.20}}
\newlabel{fig:fig13}{{20}{12}{The cumulative distribution function (CDF) for different video recording modes}{figure.20}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {21}{\ignorespaces Impact of camera shake. Our approach has the same success rate under the hand-held and the fixed modes and the performance degradation under the shaky mode is modest. }}{12}{figure.21}}
\newlabel{fig:fig14}{{21}{12}{Impact of camera shake. Our approach has the same success rate under the hand-held and the fixed modes and the performance degradation under the shaky mode is modest}{figure.21}{}}
\@writefile{lot}{\contentsline {table}{\numberline {IV}{\ignorespaces Lighting Conditions}}{12}{table.4}}
\newlabel{tab:light}{{IV}{12}{Lighting Conditions}{table.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {VI-C}}Impact of Camera Shake}{12}{subsection.6.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {22}{\ignorespaces The cracking success rate within five attempts under different lighting conditions.}}{13}{figure.22}}
\newlabel{fig:light}{{22}{13}{The cracking success rate within five attempts under different lighting conditions}{figure.22}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {23}{\ignorespaces Impact of estimation errors of filming angles.}}{13}{figure.23}}
\newlabel{fig:fig15}{{23}{13}{Impact of estimation errors of filming angles}{figure.23}{}}
\newlabel{sec:light}{{\unhbox \voidb@x \hbox {VI-D}}{13}{Impact of Lighting Conditions}{subsection.6.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {VI-D}}Impact of Lighting Conditions }{13}{subsection.6.4}}
\newlabel{sec:angle}{{\unhbox \voidb@x \hbox {VI-E}}{13}{Impact of Filming Angle Estimation}{subsection.6.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {VI-E}}Impact of Filming Angle Estimation }{13}{subsection.6.5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {VI-F}}Impact of Screen Sizes and Cameras}{13}{subsection.6.6}}
\@writefile{lot}{\contentsline {table}{\numberline {V}{\ignorespaces Screen sizes per target phone}}{14}{table.5}}
\newlabel{tab:screen-size}{{V}{14}{Screen sizes per target phone}{table.5}{}}
\@writefile{lot}{\contentsline {table}{\numberline {VI}{\ignorespaces Filming camera parameters}}{14}{table.6}}
\newlabel{tab:camera-parameters}{{VI}{14}{Filming camera parameters}{table.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {24}{\ignorespaces The cracking success rate for different target screen sizes and filming cameras. }}{14}{figure.24}}
\newlabel{fig:screen_size}{{24}{14}{The cracking success rate for different target screen sizes and filming cameras}{figure.24}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {VI-G}}Inferring Patterns with Eyes}{14}{subsection.6.7}}
\newlabel{sec:scalability}{{\unhbox \voidb@x \hbox {VI-H}}{14}{Evaluation on Other Pattern Grids}{subsection.6.8}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {VI-H}}Evaluation on Other Pattern Grids}{14}{subsection.6.8}}
\citation{shukla2014beware}
\citation{shukla2014beware}
\@writefile{lof}{\contentsline {figure}{\numberline {25}{\ignorespaces Success rates of guessing patterns through watching the video (a) or direct observations (b).}}{15}{figure.25}}
\newlabel{fig:look-unlocking process}{{25}{15}{Success rates of guessing patterns through watching the video (a) or direct observations (b)}{figure.25}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {26}{\ignorespaces Success rates of our attack for different locking grids.}}{15}{figure.26}}
\newlabel{fig:scalability}{{26}{15}{Success rates of our attack for different locking grids}{figure.26}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {27}{\ignorespaces Pattern-based and pin-based authentication interfaces from Xiaomi MI4 phone.}}{15}{figure.27}}
\newlabel{fig:unlock interface}{{27}{15}{Pattern-based and pin-based authentication interfaces from Xiaomi MI4 phone}{figure.27}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {VI-I}}Attacking PIN-base Passwords}{15}{subsection.6.9}}
\citation{biddle2012graphical,hossein2015fortifying}
\citation{zhang2015kaleido}
\citation{turk1991face}
\citation{sanchez2001iris}
\citation{androidstudy}
\@writefile{lof}{\contentsline {figure}{\numberline {28}{\ignorespaces Examples of tracked fingertip trajectory comprised of touching points. The red circle represents the touching points.}}{16}{figure.28}}
\newlabel{fig:pins_trajectory}{{28}{16}{Examples of tracked fingertip trajectory comprised of touching points. The red circle represents the touching points}{figure.28}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {29}{\ignorespaces Success rate of cracking PIN-based passwords with different number of attempts.}}{16}{figure.29}}
\newlabel{fig:pin_results}{{29}{16}{Success rate of cracking PIN-based passwords with different number of attempts}{figure.29}{}}
\@writefile{toc}{\contentsline {section}{\numberline {VII}Discussions}{16}{section.7}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {VII-A}}\leavevmode {\color  {blue}FIXED: }\leavevmode {\color  {blue}Countermeasures}}{16}{subsection.7.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {30}{\ignorespaces Examples of the variant pattern lock mechanism for defending against the video-based attacks. The red patterns are the correct pattern drawn when enrolment, and the blue dot in (c) shows that the dot is visited twice. (a) and (c) show that a previously unvisited dot can be bypassed if it is part of a horizontal, vertical or diagonal line segment of the pattern.}}{16}{figure.30}}
\newlabel{fig:protection}{{30}{16}{Examples of the variant pattern lock mechanism for defending against the video-based attacks. The red patterns are the correct pattern drawn when enrolment, and the blue dot in (c) shows that the dot is visited twice. (a) and (c) show that a previously unvisited dot can be bypassed if it is part of a horizontal, vertical or diagonal line segment of the pattern}{figure.30}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {VII-B}}Implications}{16}{subsection.7.2}}
\citation{shukla2014beware,yue2014blind}
\citation{zhang2016privacy}
\citation{de2012touch,stefan2012robustness,lingsecure,mannan2007using}
\citation{shukla2014beware}
\citation{yue2014blind}
\citation{kuhn2002compromising,xu2013seeing,raguram2011ispy,backes2009tempest}
\citation{aviv2010smudge}
\citation{zhang2016privacy}
\citation{ballard2007forgery}
\citation{serwadda2013kids}
\citation{uellenbeck2013quantifying}
\citation{alpnorway}
\citation{Yang:2002:EMT:605089.605095,Stenger:2006:MHT:1159166.1159342,citeulike:13091082}
\bibstyle{IEEEtranS}
\bibdata{refs}
\bibcite{aviv2010smudge}{{1}{}{{}}{{}}}
\bibcite{backes2009tempest}{{2}{}{{}}{{}}}
\bibcite{ballard2007forgery}{{3}{}{{}}{{}}}
\bibcite{balzarotti2008clearshot}{{4}{}{{}}{{}}}
\bibcite{citeulike:13091082}{{5}{}{{}}{{}}}
\bibcite{biddle2012graphical}{{6}{}{{}}{{}}}
\bibcite{androidstudy}{{7}{}{{}}{{}}}
\bibcite{DBLP:conf/soups/2014}{{8}{}{{}}{{}}}
\@writefile{toc}{\contentsline {section}{\numberline {VIII}Related Work}{17}{section.8}}
\@writefile{toc}{\contentsline {section}{\numberline {IX}Conclusions}{17}{section.9}}
\bibcite{DeAngeli:2005:PRW:1090412.1090419}{{9}{}{{}}{{}}}
\bibcite{de2012touch}{{10}{}{{}}{{}}}
\bibcite{egelman2014you}{{11}{}{{}}{{}}}
\bibcite{grompone2010lsd}{{12}{}{{}}{{}}}
\bibcite{hastie1996discriminant}{{13}{}{{}}{{}}}
\bibcite{TLD-toolbox-web}{{14}{}{{}}{{}}}
\bibcite{kalal2012tracking}{{15}{}{{}}{{}}}
\bibcite{Kelley2012Guess}{{16}{}{{}}{{}}}
\bibcite{kuhn2002compromising}{{17}{}{{}}{{}}}
\bibcite{Kutner2004Applied}{{18}{}{{}}{{}}}
\bibcite{lingsecure}{{19}{}{{}}{{}}}
\bibcite{alpnorway}{{20}{}{{}}{{}}}
\bibcite{mannan2007using}{{21}{}{{}}{{}}}
\bibcite{Mazurek2013Measuring}{{22}{}{{}}{{}}}
\bibcite{raguram2011ispy}{{23}{}{{}}{{}}}
\bibcite{shoulder}{{24}{}{{}}{{}}}
\bibcite{sanchez2001iris}{{25}{}{{}}{{}}}
\bibcite{serwadda2013kids}{{26}{}{{}}{{}}}
\bibcite{shukla2014beware}{{27}{}{{}}{{}}}
\bibcite{hossein2015fortifying}{{28}{}{{}}{{}}}
\bibcite{standing1970perception}{{29}{}{{}}{{}}}
\bibcite{stefan2012robustness}{{30}{}{{}}{{}}}
\bibcite{Stenger:2006:MHT:1159166.1159342}{{31}{}{{}}{{}}}
\bibcite{sun2014dissecting}{{32}{}{{}}{{}}}
\bibcite{Torralba:2002:DEI:628330.628820}{{33}{}{{}}{{}}}
\bibcite{turk1991face}{{34}{}{{}}{{}}}
\bibcite{uellenbeck2013quantifying}{{35}{}{{}}{{}}}
\bibcite{vonZezschwitz:2015:EDB:2702123.2702202}{{36}{}{{}}{{}}}
\bibcite{Weiss2008PassShapes}{{37}{}{{}}{{}}}
\bibcite{xu2013seeing}{{38}{}{{}}{{}}}
\bibcite{Yang:2002:EMT:605089.605095}{{39}{}{{}}{{}}}
\bibcite{yue2014blind}{{40}{}{{}}{{}}}
\bibcite{zhang2016privacy}{{41}{}{{}}{{}}}
\bibcite{zhang2015kaleido}{{42}{}{{}}{{}}}
\providecommand\NAT@force@numbers{}\NAT@force@numbers
